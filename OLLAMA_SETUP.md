# Настройка Ollama

## Установка Ollama

1. Перейдите на https://ollama.ai
2. Скачайте установщик для Windows
3. Запустите установщик и следуйте инструкциям
4. После установки Ollama автоматически запустится как служба Windows

## Проверка работы Ollama

После установки проверьте, что Ollama работает:

```bash
ollama list
```

Если команда выполняется без ошибок (даже если список пустой), значит Ollama работает правильно.

## Загрузка модели

Для работы бота нужна модель для генерации текста. Рекомендуется использовать `llama3`:

```bash
ollama pull llama3
```

Это может занять несколько минут, так как модель весит несколько гигабайт.

Проверьте, что модель загружена:

```bash
ollama list
```

Должна появиться строка с `llama3`.

## Важно: Не запускайте `ollama serve` вручную!

На Windows Ollama запускается автоматически как служба после установки. 

Если вы видите ошибку:
```
Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address
```

**Это нормально!** Это означает, что Ollama уже запущен и работает. Просто используйте команды `ollama pull` и `ollama list` без запуска `ollama serve`.

## Управление службой Ollama (если нужно)

Если Ollama не запускается автоматически, вы можете управлять службой:

1. Откройте "Службы" (Services):
   - Нажмите `Win + R`
   - Введите `services.msc` и нажмите Enter

2. Найдите службу "Ollama"

3. Убедитесь, что она запущена (Status = Running)

4. Если не запущена, щелкните правой кнопкой → Start

## Тестирование Ollama

Проверьте, что Ollama генерирует текст:

```bash
ollama run llama3 "Привет, как дела?"
```

Если модель отвечает, значит всё настроено правильно!

## Другие модели

Вы можете использовать другие модели вместо llama3:

- `mistral` - альтернативная модель
- `llama2` - предыдущая версия llama
- `codellama` - для программирования

Загрузите модель:
```bash
ollama pull mistral
```

И обновите переменную `OLLAMA_TEXT_MODEL` в файле `.env`:
```
OLLAMA_TEXT_MODEL=mistral
```

## Устранение проблем

### Ollama не отвечает на команды

1. Проверьте, что Ollama установлен
2. Проверьте службу Ollama в "Службы" (services.msc)
3. Перезапустите службу Ollama
4. Перезагрузите компьютер

### Модель не загружается

1. Проверьте интернет-соединение
2. Убедитесь, что есть достаточно места на диске (модели занимают несколько ГБ)
3. Попробуйте загрузить другую модель

### Порт 11434 занят

Если вы видите ошибку о том, что порт занят:
- Это означает, что Ollama уже запущен
- Не нужно запускать `ollama serve` вручную
- Просто используйте `ollama pull` и `ollama list`

## Дополнительная информация

- Официальный сайт: https://ollama.ai
- Документация: https://github.com/ollama/ollama
- Список моделей: https://ollama.ai/library




